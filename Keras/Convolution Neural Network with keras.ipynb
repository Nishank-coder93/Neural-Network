{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential     # For initializing the Neural Net\n",
    "from keras.layers import Conv2D  # 2D as we are dealing with images\n",
    "from keras.layers import MaxPooling2D  # 2D pooling for images\n",
    "from keras.layers import Flatten       # flattens the pooled image set \n",
    "from keras.layers import Dense         # Dense to bulid up layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the Convolution Neural Net\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number output of filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          width and height of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution along the width and height.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      data_format: A string,\n",
      " |          one of `channels_last` (default) or `channels_first`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `channels_last` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `channels_first`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, channels, rows, cols)` if data_format='channels_first'\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_4: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-7cf28d159abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# activation <- The function to pass the convoluted data, use ReLU to break linearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    473\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_4: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "# nb_filter <- num of convo layers \n",
    "# featuremap_rows <- num of rows in feature map\n",
    "# featuremap_cols <- num of cols in feature map\n",
    "# input_sape <- expected shape of the input shape (256,256,3) for TensorFlow backend\n",
    "# activation <- The function to pass the convoluted data, use ReLU to break linearity\n",
    "print(help(Conv2D))\n",
    "classifier.add(Conv2D(64, (3,3), input_shape=(64,64,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MaxPooling2D in module keras.layers.pooling:\n",
      "\n",
      "class MaxPooling2D(_Pooling2D)\n",
      " |  Max pooling operation for spatial data.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      pool_size: integer or tuple of 2 integers,\n",
      " |          factors by which to downscale (vertical, horizontal).\n",
      " |          (2, 2) will halve the input in both spatial dimension.\n",
      " |          If only one integer is specified, the same window length\n",
      " |          will be used for both dimensions.\n",
      " |      strides: Integer, tuple of 2 integers, or None.\n",
      " |          Strides values.\n",
      " |          If None, it will default to `pool_size`.\n",
      " |      padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      data_format: A string,\n",
      " |          one of `channels_last` (default) or `channels_first`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `channels_last` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `channels_first`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  # Input shape\n",
      " |      - If `data_format='channels_last'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, rows, cols, channels)`\n",
      " |      - If `data_format='channels_first'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, channels, rows, cols)`\n",
      " |  \n",
      " |  # Output shape\n",
      " |      - If `data_format='channels_last'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, pooled_rows, pooled_cols, channels)`\n",
      " |      - If `data_format='channels_first'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, channels, pooled_rows, pooled_cols)`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MaxPooling2D\n",
      " |      _Pooling2D\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Pooling2D:\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer max_pooling2d_4: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-ffc7ec9655f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# pool_size <- size of the Pool matrix, mostly take 2X2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    473\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer max_pooling2d_4: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Step 2 - Pooling \n",
    "# pool_size <- size of the Pool matrix, mostly take 2X2\n",
    "# print(help(MaxPooling2D))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Second Convolution Layer\n",
    "classifier.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Third Convolution Layer\n",
    "classifier.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening \n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build up the Hidden Layer of the Neural Network \n",
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build up the Output Layer of the Neural Network \n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Target size is the dimension that is expected by the CNN\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=250.0, epochs=90, validation_data=<keras.pre..., validation_steps=62.5, workers=12, max_queue_size=100)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "250/250 [==============================] - 187s - loss: 0.3012 - acc: 0.8699 - val_loss: 0.3895 - val_acc: 0.8445\n",
      "Epoch 2/90\n",
      "250/250 [==============================] - 173s - loss: 0.2992 - acc: 0.8700 - val_loss: 0.3479 - val_acc: 0.8555\n",
      "Epoch 3/90\n",
      "250/250 [==============================] - 173s - loss: 0.2988 - acc: 0.8680 - val_loss: 0.3294 - val_acc: 0.8625\n",
      "Epoch 4/90\n",
      "250/250 [==============================] - 173s - loss: 0.2839 - acc: 0.8761 - val_loss: 0.3551 - val_acc: 0.8445\n",
      "Epoch 5/90\n",
      "250/250 [==============================] - 172s - loss: 0.2825 - acc: 0.8806 - val_loss: 0.3293 - val_acc: 0.8630\n",
      "Epoch 6/90\n",
      "250/250 [==============================] - 172s - loss: 0.2805 - acc: 0.8822 - val_loss: 0.3367 - val_acc: 0.8630\n",
      "Epoch 7/90\n",
      "250/250 [==============================] - 173s - loss: 0.2843 - acc: 0.8788 - val_loss: 0.3628 - val_acc: 0.8475\n",
      "Epoch 8/90\n",
      "250/250 [==============================] - 174s - loss: 0.2596 - acc: 0.8908 - val_loss: 0.3303 - val_acc: 0.8645\n",
      "Epoch 9/90\n",
      "250/250 [==============================] - 172s - loss: 0.2701 - acc: 0.8830 - val_loss: 0.2940 - val_acc: 0.8825\n",
      "Epoch 10/90\n",
      "250/250 [==============================] - 173s - loss: 0.2656 - acc: 0.8887 - val_loss: 0.3290 - val_acc: 0.8670\n",
      "Epoch 11/90\n",
      "250/250 [==============================] - 173s - loss: 0.2457 - acc: 0.8975 - val_loss: 0.3750 - val_acc: 0.8695\n",
      "Epoch 12/90\n",
      "250/250 [==============================] - 172s - loss: 0.2548 - acc: 0.8904 - val_loss: 0.3607 - val_acc: 0.8605\n",
      "Epoch 13/90\n",
      "250/250 [==============================] - 172s - loss: 0.2523 - acc: 0.8931 - val_loss: 0.3335 - val_acc: 0.8740\n",
      "Epoch 14/90\n",
      "250/250 [==============================] - 173s - loss: 0.2408 - acc: 0.8991 - val_loss: 0.3838 - val_acc: 0.8665\n",
      "Epoch 15/90\n",
      "250/250 [==============================] - 173s - loss: 0.2425 - acc: 0.8966 - val_loss: 0.3460 - val_acc: 0.8730\n",
      "Epoch 16/90\n",
      "250/250 [==============================] - 172s - loss: 0.2359 - acc: 0.9012 - val_loss: 0.3388 - val_acc: 0.8730\n",
      "Epoch 17/90\n",
      "250/250 [==============================] - 172s - loss: 0.2313 - acc: 0.9035 - val_loss: 0.3520 - val_acc: 0.8720\n",
      "Epoch 18/90\n",
      "250/250 [==============================] - 173s - loss: 0.2317 - acc: 0.9017 - val_loss: 0.3821 - val_acc: 0.8720\n",
      "Epoch 19/90\n",
      "250/250 [==============================] - 173s - loss: 0.2215 - acc: 0.9103 - val_loss: 0.3265 - val_acc: 0.8840\n",
      "Epoch 20/90\n",
      "250/250 [==============================] - 173s - loss: 0.2104 - acc: 0.9135 - val_loss: 0.3549 - val_acc: 0.8740\n",
      "Epoch 21/90\n",
      "250/250 [==============================] - 178s - loss: 0.2165 - acc: 0.9086 - val_loss: 0.3458 - val_acc: 0.8725\n",
      "Epoch 22/90\n",
      "250/250 [==============================] - 192s - loss: 0.2108 - acc: 0.9135 - val_loss: 0.3583 - val_acc: 0.8815\n",
      "Epoch 23/90\n",
      "250/250 [==============================] - 191s - loss: 0.2180 - acc: 0.9134 - val_loss: 0.3679 - val_acc: 0.8640\n",
      "Epoch 24/90\n",
      "250/250 [==============================] - 192s - loss: 0.2113 - acc: 0.9108 - val_loss: 0.3114 - val_acc: 0.8820\n",
      "Epoch 25/90\n",
      "250/250 [==============================] - 192s - loss: 0.1970 - acc: 0.9165 - val_loss: 0.3410 - val_acc: 0.8780\n",
      "Epoch 26/90\n",
      "250/250 [==============================] - 191s - loss: 0.2057 - acc: 0.9170 - val_loss: 0.3185 - val_acc: 0.8795\n",
      "Epoch 27/90\n",
      "250/250 [==============================] - 191s - loss: 0.1993 - acc: 0.9197 - val_loss: 0.3635 - val_acc: 0.8735\n",
      "Epoch 28/90\n",
      "250/250 [==============================] - 192s - loss: 0.1979 - acc: 0.9203 - val_loss: 0.3521 - val_acc: 0.8885\n",
      "Epoch 29/90\n",
      "250/250 [==============================] - 191s - loss: 0.1984 - acc: 0.9225 - val_loss: 0.3611 - val_acc: 0.8685\n",
      "Epoch 30/90\n",
      "250/250 [==============================] - 194s - loss: 0.1924 - acc: 0.9191 - val_loss: 0.4000 - val_acc: 0.8645\n",
      "Epoch 31/90\n",
      "250/250 [==============================] - 191s - loss: 0.1963 - acc: 0.9228 - val_loss: 0.4347 - val_acc: 0.8565\n",
      "Epoch 32/90\n",
      "250/250 [==============================] - 191s - loss: 0.1872 - acc: 0.9253 - val_loss: 0.4015 - val_acc: 0.8695\n",
      "Epoch 33/90\n",
      "250/250 [==============================] - 192s - loss: 0.1837 - acc: 0.9272 - val_loss: 0.3877 - val_acc: 0.8700\n",
      "Epoch 34/90\n",
      "250/250 [==============================] - 190s - loss: 0.1808 - acc: 0.9269 - val_loss: 0.3732 - val_acc: 0.8590\n",
      "Epoch 35/90\n",
      "250/250 [==============================] - 193s - loss: 0.1826 - acc: 0.9289 - val_loss: 0.3969 - val_acc: 0.8705\n",
      "Epoch 36/90\n",
      "250/250 [==============================] - 191s - loss: 0.1834 - acc: 0.9234 - val_loss: 0.3832 - val_acc: 0.8670\n",
      "Epoch 37/90\n",
      "250/250 [==============================] - 191s - loss: 0.1707 - acc: 0.9341 - val_loss: 0.3879 - val_acc: 0.8760\n",
      "Epoch 38/90\n",
      "250/250 [==============================] - 193s - loss: 0.1751 - acc: 0.9305 - val_loss: 0.3705 - val_acc: 0.8660\n",
      "Epoch 39/90\n",
      "250/250 [==============================] - 192s - loss: 0.1748 - acc: 0.9294 - val_loss: 0.4295 - val_acc: 0.8680\n",
      "Epoch 40/90\n",
      "250/250 [==============================] - 185s - loss: 0.1790 - acc: 0.9274 - val_loss: 0.3838 - val_acc: 0.8645\n",
      "Epoch 41/90\n",
      "250/250 [==============================] - 173s - loss: 0.1624 - acc: 0.9351 - val_loss: 0.3854 - val_acc: 0.8816\n",
      "Epoch 42/90\n",
      "250/250 [==============================] - 173s - loss: 0.1679 - acc: 0.9342 - val_loss: 0.4188 - val_acc: 0.8705\n",
      "Epoch 43/90\n",
      "250/250 [==============================] - 173s - loss: 0.1700 - acc: 0.9341 - val_loss: 0.4484 - val_acc: 0.8690\n",
      "Epoch 44/90\n",
      "250/250 [==============================] - 174s - loss: 0.1649 - acc: 0.9316 - val_loss: 0.4046 - val_acc: 0.8685\n",
      "Epoch 45/90\n",
      "250/250 [==============================] - 172s - loss: 0.1641 - acc: 0.9317 - val_loss: 0.4815 - val_acc: 0.8604\n",
      "Epoch 46/90\n",
      "250/250 [==============================] - 173s - loss: 0.1704 - acc: 0.9310 - val_loss: 0.3876 - val_acc: 0.8725\n",
      "Epoch 47/90\n",
      "250/250 [==============================] - 173s - loss: 0.1618 - acc: 0.9331 - val_loss: 0.4645 - val_acc: 0.8505\n",
      "Epoch 48/90\n",
      "250/250 [==============================] - 173s - loss: 0.1619 - acc: 0.9324 - val_loss: 0.3705 - val_acc: 0.8815\n",
      "Epoch 49/90\n",
      "250/250 [==============================] - 172s - loss: 0.1580 - acc: 0.9351 - val_loss: 0.3731 - val_acc: 0.8830\n",
      "Epoch 50/90\n",
      "250/250 [==============================] - 174s - loss: 0.1638 - acc: 0.9334 - val_loss: 0.3837 - val_acc: 0.8750\n",
      "Epoch 51/90\n",
      "250/250 [==============================] - 173s - loss: 0.1527 - acc: 0.9405 - val_loss: 0.4213 - val_acc: 0.8795\n",
      "Epoch 52/90\n",
      "250/250 [==============================] - 173s - loss: 0.1423 - acc: 0.9427 - val_loss: 0.3999 - val_acc: 0.8795\n",
      "Epoch 53/90\n",
      "250/250 [==============================] - 174s - loss: 0.1382 - acc: 0.9429 - val_loss: 0.4295 - val_acc: 0.8825\n",
      "Epoch 54/90\n",
      "250/250 [==============================] - 175s - loss: 0.1418 - acc: 0.9441 - val_loss: 0.4528 - val_acc: 0.8700\n",
      "Epoch 55/90\n",
      "250/250 [==============================] - 173s - loss: 0.1500 - acc: 0.9424 - val_loss: 0.4369 - val_acc: 0.8855\n",
      "Epoch 56/90\n",
      "250/250 [==============================] - 174s - loss: 0.1483 - acc: 0.9391 - val_loss: 0.3910 - val_acc: 0.8765\n",
      "Epoch 57/90\n",
      "250/250 [==============================] - 174s - loss: 0.1427 - acc: 0.9449 - val_loss: 0.4165 - val_acc: 0.8760\n",
      "Epoch 58/90\n",
      "250/250 [==============================] - 175s - loss: 0.1432 - acc: 0.9430 - val_loss: 0.4071 - val_acc: 0.8845\n",
      "Epoch 59/90\n",
      "250/250 [==============================] - 174s - loss: 0.1424 - acc: 0.9449 - val_loss: 0.3760 - val_acc: 0.8790\n",
      "Epoch 60/90\n",
      "250/250 [==============================] - 176s - loss: 0.1351 - acc: 0.9461 - val_loss: 0.4091 - val_acc: 0.8890\n",
      "Epoch 61/90\n",
      "250/250 [==============================] - 174s - loss: 0.1465 - acc: 0.9416 - val_loss: 0.3627 - val_acc: 0.8835\n",
      "Epoch 62/90\n",
      "250/250 [==============================] - 173s - loss: 0.1321 - acc: 0.9494 - val_loss: 0.3932 - val_acc: 0.8825\n",
      "Epoch 63/90\n",
      "250/250 [==============================] - 174s - loss: 0.1513 - acc: 0.9381 - val_loss: 0.4502 - val_acc: 0.8795\n",
      "Epoch 64/90\n",
      "250/250 [==============================] - 174s - loss: 0.1355 - acc: 0.9461 - val_loss: 0.4093 - val_acc: 0.8785\n",
      "Epoch 65/90\n",
      "250/250 [==============================] - 174s - loss: 0.1387 - acc: 0.9445 - val_loss: 0.3659 - val_acc: 0.8965\n",
      "Epoch 66/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 173s - loss: 0.1469 - acc: 0.9420 - val_loss: 0.3998 - val_acc: 0.8865\n",
      "Epoch 67/90\n",
      "250/250 [==============================] - 173s - loss: 0.1416 - acc: 0.9406 - val_loss: 0.3827 - val_acc: 0.8945\n",
      "Epoch 68/90\n",
      "250/250 [==============================] - 173s - loss: 0.1398 - acc: 0.9420 - val_loss: 0.4381 - val_acc: 0.8855\n",
      "Epoch 69/90\n",
      "250/250 [==============================] - 173s - loss: 0.1404 - acc: 0.9434 - val_loss: 0.3914 - val_acc: 0.8805\n",
      "Epoch 70/90\n",
      "250/250 [==============================] - 172s - loss: 0.1316 - acc: 0.9494 - val_loss: 0.4159 - val_acc: 0.8725\n",
      "Epoch 71/90\n",
      "250/250 [==============================] - 173s - loss: 0.1269 - acc: 0.9527 - val_loss: 0.3743 - val_acc: 0.8830\n",
      "Epoch 72/90\n",
      "250/250 [==============================] - 173s - loss: 0.1289 - acc: 0.9474 - val_loss: 0.3989 - val_acc: 0.8690\n",
      "Epoch 73/90\n",
      "250/250 [==============================] - 174s - loss: 0.1248 - acc: 0.9521 - val_loss: 0.4200 - val_acc: 0.8775\n",
      "Epoch 74/90\n",
      "250/250 [==============================] - 173s - loss: 0.1278 - acc: 0.9503 - val_loss: 0.4575 - val_acc: 0.8775\n",
      "Epoch 75/90\n",
      "250/250 [==============================] - 173s - loss: 0.1298 - acc: 0.9511 - val_loss: 0.4630 - val_acc: 0.8785\n",
      "Epoch 76/90\n",
      "250/250 [==============================] - 173s - loss: 0.1339 - acc: 0.9478 - val_loss: 0.3873 - val_acc: 0.8775\n",
      "Epoch 77/90\n",
      "250/250 [==============================] - 173s - loss: 0.1238 - acc: 0.9516 - val_loss: 0.3826 - val_acc: 0.8830\n",
      "Epoch 78/90\n",
      "250/250 [==============================] - 172s - loss: 0.1328 - acc: 0.9489 - val_loss: 0.3875 - val_acc: 0.8740\n",
      "Epoch 79/90\n",
      "250/250 [==============================] - 173s - loss: 0.1255 - acc: 0.9507 - val_loss: 0.4350 - val_acc: 0.8670\n",
      "Epoch 80/90\n",
      "250/250 [==============================] - 172s - loss: 0.1316 - acc: 0.9461 - val_loss: 0.4202 - val_acc: 0.8795\n",
      "Epoch 81/90\n",
      "250/250 [==============================] - 177s - loss: 0.1141 - acc: 0.9547 - val_loss: 0.4118 - val_acc: 0.8785\n",
      "Epoch 82/90\n",
      "250/250 [==============================] - 175s - loss: 0.1280 - acc: 0.9489 - val_loss: 0.4906 - val_acc: 0.8690\n",
      "Epoch 83/90\n",
      "250/250 [==============================] - 173s - loss: 0.1309 - acc: 0.9509 - val_loss: 0.4307 - val_acc: 0.8805\n",
      "Epoch 84/90\n",
      "250/250 [==============================] - 172s - loss: 0.1196 - acc: 0.9543 - val_loss: 0.3785 - val_acc: 0.8861\n",
      "Epoch 85/90\n",
      "250/250 [==============================] - 174s - loss: 0.1191 - acc: 0.9540 - val_loss: 0.4714 - val_acc: 0.8755\n",
      "Epoch 86/90\n",
      "250/250 [==============================] - 173s - loss: 0.1159 - acc: 0.9551 - val_loss: 0.4588 - val_acc: 0.8665\n",
      "Epoch 87/90\n",
      "250/250 [==============================] - 172s - loss: 0.1256 - acc: 0.9503 - val_loss: 0.4695 - val_acc: 0.8680\n",
      "Epoch 88/90\n",
      "250/250 [==============================] - 173s - loss: 0.1198 - acc: 0.9535 - val_loss: 0.4473 - val_acc: 0.8750\n",
      "Epoch 89/90\n",
      "250/250 [==============================] - 173s - loss: 0.1241 - acc: 0.9524 - val_loss: 0.3812 - val_acc: 0.8795\n",
      "Epoch 90/90\n",
      "250/250 [==============================] - 173s - loss: 0.1179 - acc: 0.9576 - val_loss: 0.3882 - val_acc: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e310a58>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the CNN Model \n",
    "classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=8000/batch_size, # Num of samples can be taken as steps\n",
    "                    epochs=90,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=2000/ batch_size, # Corresponds to num of samples in the test\n",
    "                    workers = 12,\n",
    "                    max_q_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save('model_test.h5')\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAhYklEQVR4nG26ebCt2VUftoY9fN+Z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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x128781080>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image\n",
    "test_single_image = image.load_img('dataset/single_prediction/cat_or_dog_5.jpg', target_size=(64,64))\n",
    "test_single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the Image into an array\n",
    "test_single_image = image.img_to_array(test_single_image)\n",
    "test_single_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a new dimension to the image where axis is the position to specify the index\n",
    "test_single_image = np.expand_dims(test_single_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier.predict(test_single_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a Dog !! Woof woof\n"
     ]
    }
   ],
   "source": [
    "def res_conversion(val):\n",
    "    if val == 1:\n",
    "        print(\"it is a Dog !! Woof woof\")\n",
    "    else:\n",
    "        print(\"it is a Cat !! meowww\")\n",
    "\n",
    "res_conversion(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing saved model \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_test.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer= 'adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "it is a Cat !! meowww\n"
     ]
    }
   ],
   "source": [
    "res_val = model.predict_classes(test_single_image)\n",
    "res_conversion(res_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential     # For initializing the Neural Net\n",
    "from keras.layers import Conv2D  # 2D as we are dealing with images\n",
    "from keras.layers import MaxPooling2D  # 2D pooling for images\n",
    "from keras.layers import Flatten       # flattens the pooled image set \n",
    "from keras.layers import Dense         # Dense to bulid up layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the Convolution Neural Net\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "# nb_filter <- num of convo layers \n",
    "# featuremap_rows <- num of rows in feature map\n",
    "# featuremap_cols <- num of cols in feature map\n",
    "# input_sape <- expected shape of the input shape (256,256,3) for TensorFlow backend\n",
    "# activation <- The function to pass the convoluted data, use ReLU to break linearity\n",
    "# print(help(Conv2D))\n",
    "classifier.add(Conv2D(64, (3,3), input_shape=(64,64,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Pooling \n",
    "# pool_size <- size of the Pool matrix, mostly take 2X2\n",
    "# print(help(MaxPooling2D))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Second Convolution Layer\n",
    "classifier.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Third Convolution Layer\n",
    "classifier.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening \n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build up the Hidden Layer of the Neural Network \n",
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build up the Output Layer of the Neural Network \n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Target size is the dimension that is expected by the CNN\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mac-NB/Envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=250.0, epochs=90, validation_data=<keras.pre..., validation_steps=62.5, workers=12, max_queue_size=100)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "250/250 [==============================] - 212s - loss: 0.6775 - acc: 0.5606 - val_loss: 0.6860 - val_acc: 0.5750\n",
      "Epoch 2/90\n",
      "250/250 [==============================] - 165s - loss: 0.6315 - acc: 0.6401 - val_loss: 0.5929 - val_acc: 0.6905\n",
      "Epoch 3/90\n",
      "250/250 [==============================] - 162s - loss: 0.5923 - acc: 0.6814 - val_loss: 0.5579 - val_acc: 0.7270\n",
      "Epoch 4/90\n",
      "250/250 [==============================] - 159s - loss: 0.5582 - acc: 0.7212 - val_loss: 0.5034 - val_acc: 0.7560\n",
      "Epoch 5/90\n",
      "250/250 [==============================] - 155s - loss: 0.5200 - acc: 0.7445 - val_loss: 0.4865 - val_acc: 0.7695\n",
      "Epoch 6/90\n",
      "250/250 [==============================] - 154s - loss: 0.4899 - acc: 0.7654 - val_loss: 0.4335 - val_acc: 0.8010\n",
      "Epoch 7/90\n",
      "250/250 [==============================] - 154s - loss: 0.4673 - acc: 0.7794 - val_loss: 0.4441 - val_acc: 0.7840\n",
      "Epoch 8/90\n",
      "250/250 [==============================] - 155s - loss: 0.4508 - acc: 0.7902 - val_loss: 0.4506 - val_acc: 0.7855\n",
      "Epoch 9/90\n",
      "250/250 [==============================] - 156s - loss: 0.4356 - acc: 0.7993 - val_loss: 0.4007 - val_acc: 0.8150\n",
      "Epoch 10/90\n",
      "250/250 [==============================] - 155s - loss: 0.4168 - acc: 0.8115 - val_loss: 0.3776 - val_acc: 0.8280\n",
      "Epoch 11/90\n",
      "250/250 [==============================] - 158s - loss: 0.4065 - acc: 0.8161 - val_loss: 0.4063 - val_acc: 0.8210\n",
      "Epoch 12/90\n",
      "250/250 [==============================] - 155s - loss: 0.3976 - acc: 0.8214 - val_loss: 0.3675 - val_acc: 0.8295\n",
      "Epoch 13/90\n",
      "250/250 [==============================] - 157s - loss: 0.3789 - acc: 0.8337 - val_loss: 0.3769 - val_acc: 0.8245\n",
      "Epoch 14/90\n",
      "250/250 [==============================] - 155s - loss: 0.3713 - acc: 0.8341 - val_loss: 0.3503 - val_acc: 0.8490\n",
      "Epoch 15/90\n",
      "250/250 [==============================] - 155s - loss: 0.3540 - acc: 0.8429 - val_loss: 0.3447 - val_acc: 0.8565\n",
      "Epoch 16/90\n",
      "250/250 [==============================] - 155s - loss: 0.3512 - acc: 0.8438 - val_loss: 0.3669 - val_acc: 0.8370\n",
      "Epoch 17/90\n",
      "250/250 [==============================] - 155s - loss: 0.3454 - acc: 0.8421 - val_loss: 0.3465 - val_acc: 0.8443\n",
      "Epoch 18/90\n",
      "250/250 [==============================] - 156s - loss: 0.3406 - acc: 0.8526 - val_loss: 0.3825 - val_acc: 0.8370\n",
      "Epoch 19/90\n",
      "250/250 [==============================] - 156s - loss: 0.3310 - acc: 0.8534 - val_loss: 0.3632 - val_acc: 0.8305\n",
      "Epoch 20/90\n",
      "250/250 [==============================] - 157s - loss: 0.3238 - acc: 0.8603 - val_loss: 0.3522 - val_acc: 0.8550\n",
      "Epoch 21/90\n",
      "250/250 [==============================] - 158s - loss: 0.3088 - acc: 0.8690 - val_loss: 0.3420 - val_acc: 0.8564\n",
      "Epoch 22/90\n",
      "250/250 [==============================] - 155s - loss: 0.3107 - acc: 0.8690 - val_loss: 0.3704 - val_acc: 0.8530\n",
      "Epoch 23/90\n",
      "250/250 [==============================] - 157s - loss: 0.2997 - acc: 0.8736 - val_loss: 0.3276 - val_acc: 0.8630\n",
      "Epoch 24/90\n",
      "250/250 [==============================] - 157s - loss: 0.2950 - acc: 0.8762 - val_loss: 0.3470 - val_acc: 0.8635\n",
      "Epoch 25/90\n",
      "250/250 [==============================] - 157s - loss: 0.2780 - acc: 0.8806 - val_loss: 0.3638 - val_acc: 0.8548\n",
      "Epoch 26/90\n",
      "250/250 [==============================] - 164s - loss: 0.2896 - acc: 0.8689 - val_loss: 0.3290 - val_acc: 0.8605\n",
      "Epoch 27/90\n",
      "250/250 [==============================] - 165s - loss: 0.2802 - acc: 0.8772 - val_loss: 0.3688 - val_acc: 0.8385\n",
      "Epoch 28/90\n",
      "250/250 [==============================] - 166s - loss: 0.2796 - acc: 0.8788 - val_loss: 0.3208 - val_acc: 0.8735\n",
      "Epoch 29/90\n",
      "250/250 [==============================] - 164s - loss: 0.2659 - acc: 0.8879 - val_loss: 0.3348 - val_acc: 0.8755\n",
      "Epoch 30/90\n",
      "250/250 [==============================] - 165s - loss: 0.2695 - acc: 0.8841 - val_loss: 0.3344 - val_acc: 0.8635\n",
      "Epoch 31/90\n",
      "250/250 [==============================] - 164s - loss: 0.2627 - acc: 0.8918 - val_loss: 0.3382 - val_acc: 0.8745\n",
      "Epoch 32/90\n",
      "250/250 [==============================] - 165s - loss: 0.2506 - acc: 0.8951 - val_loss: 0.3224 - val_acc: 0.8655\n",
      "Epoch 33/90\n",
      "250/250 [==============================] - 165s - loss: 0.2503 - acc: 0.8946 - val_loss: 0.3432 - val_acc: 0.8695\n",
      "Epoch 34/90\n",
      "250/250 [==============================] - 165s - loss: 0.2468 - acc: 0.8969 - val_loss: 0.3232 - val_acc: 0.8725\n",
      "Epoch 35/90\n",
      "250/250 [==============================] - 164s - loss: 0.2423 - acc: 0.8994 - val_loss: 0.3005 - val_acc: 0.8835\n",
      "Epoch 36/90\n",
      "250/250 [==============================] - 167s - loss: 0.2449 - acc: 0.8969 - val_loss: 0.3235 - val_acc: 0.8625\n",
      "Epoch 37/90\n",
      "250/250 [==============================] - 165s - loss: 0.2406 - acc: 0.8996 - val_loss: 0.3266 - val_acc: 0.8674\n",
      "Epoch 38/90\n",
      "250/250 [==============================] - 166s - loss: 0.2405 - acc: 0.9004 - val_loss: 0.3332 - val_acc: 0.8670\n",
      "Epoch 39/90\n",
      "250/250 [==============================] - 164s - loss: 0.2251 - acc: 0.9024 - val_loss: 0.3176 - val_acc: 0.8700\n",
      "Epoch 40/90\n",
      "250/250 [==============================] - 167s - loss: 0.2300 - acc: 0.9066 - val_loss: 0.3599 - val_acc: 0.8625\n",
      "Epoch 41/90\n",
      "250/250 [==============================] - 165s - loss: 0.2263 - acc: 0.9060 - val_loss: 0.3282 - val_acc: 0.8750\n",
      "Epoch 42/90\n",
      "250/250 [==============================] - 169s - loss: 0.2161 - acc: 0.9106 - val_loss: 0.3515 - val_acc: 0.8705\n",
      "Epoch 43/90\n",
      "250/250 [==============================] - 168s - loss: 0.2117 - acc: 0.9089 - val_loss: 0.3513 - val_acc: 0.8765\n",
      "Epoch 44/90\n",
      "250/250 [==============================] - 166s - loss: 0.2164 - acc: 0.9108 - val_loss: 0.3189 - val_acc: 0.8730\n",
      "Epoch 45/90\n",
      "250/250 [==============================] - 165s - loss: 0.2161 - acc: 0.9089 - val_loss: 0.3473 - val_acc: 0.8590\n",
      "Epoch 46/90\n",
      "250/250 [==============================] - 167s - loss: 0.2119 - acc: 0.9119 - val_loss: 0.3223 - val_acc: 0.8750\n",
      "Epoch 47/90\n",
      "250/250 [==============================] - 163s - loss: 0.1954 - acc: 0.9196 - val_loss: 0.3618 - val_acc: 0.8740\n",
      "Epoch 48/90\n",
      "250/250 [==============================] - 159s - loss: 0.2006 - acc: 0.9152 - val_loss: 0.3525 - val_acc: 0.8735\n",
      "Epoch 49/90\n",
      "250/250 [==============================] - 150s - loss: 0.2029 - acc: 0.9131 - val_loss: 0.3328 - val_acc: 0.8670\n",
      "Epoch 50/90\n",
      "250/250 [==============================] - 150s - loss: 0.1960 - acc: 0.9193 - val_loss: 0.3925 - val_acc: 0.8670\n",
      "Epoch 51/90\n",
      "250/250 [==============================] - 151s - loss: 0.2037 - acc: 0.9147 - val_loss: 0.3793 - val_acc: 0.8630\n",
      "Epoch 52/90\n",
      "250/250 [==============================] - 149s - loss: 0.1884 - acc: 0.9221 - val_loss: 0.3725 - val_acc: 0.8665\n",
      "Epoch 53/90\n",
      "250/250 [==============================] - 149s - loss: 0.1961 - acc: 0.9197 - val_loss: 0.3524 - val_acc: 0.8674\n",
      "Epoch 54/90\n",
      "250/250 [==============================] - 150s - loss: 0.1943 - acc: 0.9204 - val_loss: 0.3233 - val_acc: 0.8750\n",
      "Epoch 55/90\n",
      "250/250 [==============================] - 151s - loss: 0.1813 - acc: 0.9250 - val_loss: 0.3265 - val_acc: 0.8755\n",
      "Epoch 56/90\n",
      "250/250 [==============================] - 151s - loss: 0.1890 - acc: 0.9230 - val_loss: 0.3395 - val_acc: 0.8625\n",
      "Epoch 57/90\n",
      "250/250 [==============================] - 150s - loss: 0.1764 - acc: 0.9279 - val_loss: 0.3372 - val_acc: 0.8730\n",
      "Epoch 58/90\n",
      "250/250 [==============================] - 150s - loss: 0.1688 - acc: 0.9311 - val_loss: 0.5106 - val_acc: 0.8370\n",
      "Epoch 59/90\n",
      "250/250 [==============================] - 150s - loss: 0.1952 - acc: 0.9193 - val_loss: 0.3738 - val_acc: 0.8660\n",
      "Epoch 60/90\n",
      "250/250 [==============================] - 151s - loss: 0.1722 - acc: 0.9306 - val_loss: 0.3781 - val_acc: 0.8860\n",
      "Epoch 61/90\n",
      "250/250 [==============================] - 150s - loss: 0.1773 - acc: 0.9283 - val_loss: 0.4123 - val_acc: 0.8625\n",
      "Epoch 62/90\n",
      "250/250 [==============================] - 150s - loss: 0.1722 - acc: 0.9310 - val_loss: 0.3369 - val_acc: 0.8760\n",
      "Epoch 63/90\n",
      "250/250 [==============================] - 152s - loss: 0.1657 - acc: 0.9310 - val_loss: 0.3827 - val_acc: 0.8825\n",
      "Epoch 64/90\n",
      "250/250 [==============================] - 150s - loss: 0.1834 - acc: 0.9265 - val_loss: 0.3478 - val_acc: 0.8775\n",
      "Epoch 65/90\n",
      "250/250 [==============================] - 151s - loss: 0.1694 - acc: 0.9286 - val_loss: 0.3862 - val_acc: 0.8760\n",
      "Epoch 66/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 153s - loss: 0.1709 - acc: 0.9296 - val_loss: 0.3630 - val_acc: 0.8670\n",
      "Epoch 67/90\n",
      "250/250 [==============================] - 150s - loss: 0.1681 - acc: 0.9330 - val_loss: 0.3440 - val_acc: 0.8735\n",
      "Epoch 68/90\n",
      "250/250 [==============================] - 150s - loss: 0.1662 - acc: 0.9335 - val_loss: 0.3649 - val_acc: 0.8830\n",
      "Epoch 69/90\n",
      "250/250 [==============================] - 152s - loss: 0.1686 - acc: 0.9316 - val_loss: 0.3930 - val_acc: 0.8805\n",
      "Epoch 70/90\n",
      "250/250 [==============================] - 151s - loss: 0.1562 - acc: 0.9379 - val_loss: 0.5398 - val_acc: 0.8425\n",
      "Epoch 71/90\n",
      "250/250 [==============================] - 150s - loss: 0.1646 - acc: 0.9374 - val_loss: 0.3857 - val_acc: 0.8735\n",
      "Epoch 72/90\n",
      "250/250 [==============================] - 152s - loss: 0.1629 - acc: 0.9331 - val_loss: 0.3977 - val_acc: 0.8675\n",
      "Epoch 73/90\n",
      "250/250 [==============================] - 151s - loss: 0.1602 - acc: 0.9396 - val_loss: 0.3579 - val_acc: 0.8790\n",
      "Epoch 74/90\n",
      "250/250 [==============================] - 150s - loss: 0.1535 - acc: 0.9397 - val_loss: 0.4122 - val_acc: 0.8685\n",
      "Epoch 75/90\n",
      "250/250 [==============================] - 152s - loss: 0.1513 - acc: 0.9405 - val_loss: 0.4265 - val_acc: 0.8720\n",
      "Epoch 76/90\n",
      "250/250 [==============================] - 150s - loss: 0.1580 - acc: 0.9380 - val_loss: 0.3879 - val_acc: 0.8710\n",
      "Epoch 77/90\n",
      "250/250 [==============================] - 150s - loss: 0.1520 - acc: 0.9401 - val_loss: 0.4102 - val_acc: 0.8780\n",
      "Epoch 78/90\n",
      "250/250 [==============================] - 152s - loss: 0.1570 - acc: 0.9376 - val_loss: 0.4007 - val_acc: 0.8660\n",
      "Epoch 79/90\n",
      "250/250 [==============================] - 151s - loss: 0.1474 - acc: 0.9415 - val_loss: 0.4129 - val_acc: 0.8675\n",
      "Epoch 80/90\n",
      "250/250 [==============================] - 152s - loss: 0.1455 - acc: 0.9429 - val_loss: 0.3987 - val_acc: 0.8880\n",
      "Epoch 81/90\n",
      "250/250 [==============================] - 150s - loss: 0.1588 - acc: 0.9359 - val_loss: 0.3885 - val_acc: 0.8740\n",
      "Epoch 82/90\n",
      "250/250 [==============================] - 150s - loss: 0.1387 - acc: 0.9429 - val_loss: 0.4143 - val_acc: 0.8715\n",
      "Epoch 83/90\n",
      "250/250 [==============================] - 152s - loss: 0.1460 - acc: 0.9414 - val_loss: 0.3758 - val_acc: 0.8785\n",
      "Epoch 84/90\n",
      "250/250 [==============================] - 150s - loss: 0.1394 - acc: 0.9452 - val_loss: 0.3928 - val_acc: 0.8715\n",
      "Epoch 85/90\n",
      "250/250 [==============================] - 149s - loss: 0.1458 - acc: 0.9415 - val_loss: 0.3778 - val_acc: 0.8780\n",
      "Epoch 86/90\n",
      "250/250 [==============================] - 150s - loss: 0.1410 - acc: 0.9427 - val_loss: 0.3746 - val_acc: 0.8820\n",
      "Epoch 87/90\n",
      "250/250 [==============================] - 152s - loss: 0.1448 - acc: 0.9416 - val_loss: 0.3995 - val_acc: 0.8775\n",
      "Epoch 88/90\n",
      "250/250 [==============================] - 150s - loss: 0.1300 - acc: 0.9501 - val_loss: 0.4051 - val_acc: 0.8755\n",
      "Epoch 89/90\n",
      "250/250 [==============================] - 152s - loss: 0.1358 - acc: 0.9470 - val_loss: 0.3397 - val_acc: 0.8775\n",
      "Epoch 90/90\n",
      "250/250 [==============================] - 153s - loss: 0.1296 - acc: 0.9447 - val_loss: 0.3851 - val_acc: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111671048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the CNN Model \n",
    "classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=8000/batch_size, # Num of samples can be taken as steps\n",
    "                    epochs=90,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=2000/ batch_size, # Corresponds to num of samples in the test\n",
    "                    workers = 12,\n",
    "                    max_q_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save('model_test.h5')\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAjZ0lEQVR4nD26abSm11Xnt4dznvEd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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x112A90080>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image\n",
    "test_single_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))\n",
    "test_single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the Image into an array\n",
    "test_single_image = image.img_to_array(test_single_image)\n",
    "test_single_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a new dimension to the image where axis is the position to specify the index\n",
    "test_single_image = np.expand_dims(test_single_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier.predict(test_single_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a Dog !! Woof woof\n"
     ]
    }
   ],
   "source": [
    "def res_conversion(val):\n",
    "    if val == 1:\n",
    "        print(\"it is a Dog !! Woof woof\")\n",
    "    else:\n",
    "        print(\"it is a Cat !! meowww\")\n",
    "\n",
    "res_conversion(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing saved model \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = load_model('model_test.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer= 'adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "it is a Dog !! Woof woof\n"
     ]
    }
   ],
   "source": [
    "res_val = model.predict_classes(test_single_image)\n",
    "res_conversion(res_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
